{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>PyData Indy - Jupyter Web Scraper - Wunderground</h1></center>\n",
    "![Image of Wunderground Logo](http://cordcutting.com/images/kodi-images/weather-wunderground.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>INTRO:</b>\n",
    "\n",
    "One of the most critical elements of data science begins simply with having access to information through a variety of modern file formats.  This excersise will help highlight a few examples of collecting data through web scraping and accessing these sources with the modern Python data stack.  Whether you find yourself working with sources like flat files, XML, or JSON data, tools demonstrated in this exercise will be a valuable asset to your efforts.  Our scope in this example will primarily use the Numpy, Pandas, & Matplotlib libraries for this exercise.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center><a href=\"http://docs.scipy.org/doc/numpy-dev/dev\"> Numpy Docs </a></center>\n",
    "<center><a href=\"http://pandas.pydata.org/pandas-docs/stable\"> Pandas Docs </a></center>\n",
    "<center><a href=\"http://matplotlib.org/contents.html#\"> Matplotlib Docs </a></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>ABOUT OUR DATA:</b>\n",
    "<br><br>\n",
    "<a href=\"http://docs.scipy.org/doc/numpy-dev/dev\"> Wunderground</a> is a popular source for weather data.  This demo will utilize a few pre-built .py files to help us scrape historical web data by using (1) urllib.requests and (2) BeautifulSoup to fetch our data, parse the contents, and return it to a local CSV file for analysis and visualization.\n",
    "\n",
    "To follow along with this example, we will be using \"%run filename.py\" as a convention for active code cells.  Our order of operation is:\n",
    "<br><br>\n",
    "<i>(1) %run wunderground_scraper.py (uses urllib.requets to dynamically fetch HTML)<br>\n",
    "(2) %run wunderground_parser.py (uses BeautifulSoup to parse the stored HTML and return data as a local CSV)<br>\n",
    "(3) Use Numpy, Pandas, and Matplotlib to explore the data we've collected.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%run wunderground_scraper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%run wunderground_parser.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv('KIND-FULL-YEAR.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_data.set_index(['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Establish a 'day_order' as a given range for all parsed dates from our scrape.\n",
    "weather_data_subset = weather_data[weather_data['date'] >= datetime(year=2015, month=3, day=1)]\n",
    "weather_data_subset = weather_data_subset[weather_data_subset['date'] < datetime(year=2016, month=3, day=1)].copy()\n",
    "weather_data_subset['day_order'] = range(len(weather_data_subset))\n",
    "\n",
    "# Create derived data for our 'day_order' axis & obtain the values of individual fields.\n",
    "day_order = weather_data_subset['day_order']\n",
    "record_max_temps = weather_data_subset['record_max_temp'].values\n",
    "record_min_temps = weather_data_subset['record_min_temp'].values\n",
    "average_max_temps = weather_data_subset['average_max_temp'].values\n",
    "average_min_temps = weather_data_subset['average_min_temp'].values\n",
    "actual_max_temps = weather_data_subset['actual_max_temp'].values\n",
    "actual_min_temps = weather_data_subset['actual_min_temp'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "# Layer #1 - Red range of bars showing RECORD High and low\n",
    "record_temp_plot = plt.bar(day_order, record_max_temps - record_min_temps, bottom=record_min_temps,\n",
    "        edgecolor='none', color='#CD5C5C', width=1, label='Record')\n",
    "\n",
    "# Layer #2 - Blue range of bars showing AVERAGE Highs and lows\n",
    "average_temp_plot = plt.bar(day_order, average_max_temps - average_min_temps, bottom=average_min_temps,\n",
    "        edgecolor='none', color='#5F9EA0', width=1, label='Average')\n",
    "\n",
    "# Layer #3 - Grey range of bars showing ACTUAL Highs and Lows\n",
    "actual_temp_plot = plt.bar(day_order, actual_max_temps - actual_min_temps, bottom=actual_min_temps,\n",
    "        edgecolor='black', linewidth=0.5, color='#808080', width=1, label='Actual')\n",
    "\n",
    "# Formatting the Limits for our X and Y axes.\n",
    "plt.ylim(-15, 111)\n",
    "plt.xlim(-5, 370)\n",
    "\n",
    "# Scale & Label our Y axis for Temperature (Far.)\n",
    "plt.yticks(range(-10, 111, 10), [r'{}$^\\circ$'.format(x)\n",
    "                                 for x in range(-10, 111, 10)], fontsize=10)\n",
    "plt.ylabel(r'Temperature ($^\\circ$F)', fontsize=12)\n",
    "\n",
    "# Assign our X axis units of days of the year\n",
    "month_beginning_df = weather_data_subset[weather_data_subset['date'].apply(lambda x: True if x.day == 1 else False)]\n",
    "month_beginning_indeces = list(month_beginning_df['day_order'].values)\n",
    "month_beginning_names = list(month_beginning_df['date'].apply(lambda x: x.strftime(\"%B\")).values)\n",
    "month_beginning_names[0] += '\\n\\'15'\n",
    "month_beginning_names[10] += '\\n\\'16'\n",
    "\n",
    "# Manual add the last month label.\n",
    "month_beginning_indeces += [weather_data_subset['day_order'].values[-1]]\n",
    "month_beginning_names += ['March']\n",
    "plt.xticks(month_beginning_indeces,\n",
    "           month_beginning_names,\n",
    "           fontsize=10)\n",
    "\n",
    "ax2 = ax1.twiny()\n",
    "plt.xticks(month_beginning_indeces,\n",
    "           month_beginning_names,\n",
    "           fontsize=10)\n",
    "\n",
    "plt.xlim(-5, 370)\n",
    "plt.grid(False)\n",
    "\n",
    "ax3 = ax1.twinx()\n",
    "plt.yticks(range(-10, 111, 10), [r'{}$^\\circ$'.format(x)\n",
    "                                 for x in range(-10, 111, 10)], fontsize=10)\n",
    "plt.ylim(-15, 111)\n",
    "plt.grid(False)\n",
    "\n",
    "#plt.legend()\n",
    "#plt.title('Indianapolis, IN\\'s weather, March 2015 - March 2016\\n\\n', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
